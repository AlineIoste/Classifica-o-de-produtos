{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linha de Raciocínio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição do Problema:\n",
    "\n",
    "Construção de um classificador de produtos que recebe um conjunto de características de um produto e retorna a categoria dele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 : Anaĺise dos campos que podem ser considerados classificatórios para a identificação do produto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset disponivel para a solução do problema é composto de uma amostragem de dados da plataforma do Elo7.\n",
    "O Elo7 é o maior site brasileiro de compra e venda de artesanato.\n",
    "Através da plataforma online compradores podem compra diretamente de milhares de pessoas que transformam ideias criativas em produtos únicos e diferenciados.\n",
    "o dataset disponivel contém 38.507 registros distribuídos em 5 categorias (Bebê, Bijuterias e Jóias, Decoração, Lembrancinhas, Papel e Cia e Outros).\n",
    "Estes registros foram gerados através de cada clique em um produto a partir de um termo de busca do usuário no site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir um modelo classificador de produtos a partir de suas características precisamos analisar se existem campos disponiveis no dataset que são determinantes para a identificação da categoria dos produtos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitivamente baseado no nosso conhecimento do negocio e fazendo uma analogia dos campos que usamos para identificar os produtos podemos avaliar os campos que seriam determinantes para identificar a categoria dos produtos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma análise intuitiva dos campos disponivel no dataset podemos avaliar item a item do dataset, como uma visão prévia dos possiveis candidatos.\n",
    "\n",
    "#### 1: product_id - identificação de produto\n",
    "** Não é um fator determinante para a identificação do produto, número sem qualquer correlação com a categoria.\n",
    "\n",
    "#### 2: seller_id - identificação do vendedor\n",
    "** Não é um fator determinante para a identificação do produto, número de identificação do vendedor, podendo vender qualquer categoria e não sendo uma caracteristica do produto.\n",
    "\n",
    "#### 3: query - termo de busca inserido pelo usuário\n",
    "** Forte candidato por ser termos cadastrados pelo vendedor para retornar o produto, ou sejam são incluidas aqui caracterististicas que determimam o produto.\n",
    "\n",
    "#### 4: search_page - número da página que o produto apareceu nos resultados de busca (mín 1 e máx 5)\n",
    "** Não é um fator determinante para a identificação do produto, não importante para caracteristica do produto.\n",
    "\n",
    "#### 5: position - número da posição que o produto apareceu dentro da página de busca (mín 0 e máx 38)\n",
    "** Não é um fator determinante para a identificação do produto, não é importante para caracteristica do produto.\n",
    "\n",
    "#### 6: title - título do produto\n",
    "** Forte candidato por possuir termos cadastrados pelo vendedor para o produto, ou sejam são incluidas aqui caracterististicas que determimam o produto.\n",
    "    \n",
    "#### 7: concatenated_tags - tags do produto inseridas pelo vendedor (as tags estão concatenadas por espaço)\n",
    "** Forte candidato por possuir termos cadastrados pelo vendedor para retornar o produto, ou sejam são incluidas aqui caracterististicas que determimam o produto.\n",
    "\n",
    "#### 8: creation_date - data de criação do produto na plataforma do Elo7\n",
    "** Não é um fator determinante para a identificação do produto, não importante para caracteristica do produto.\n",
    "    \n",
    "#### 9: price - preço do produto em reais\n",
    "** Neste caso deve ser feito uma análise exploratória das distribuições de preços por categorias para identificar se tem alguma correlação do preço com a categorias.\n",
    "Muito provavelmente terá uma alta distribuição, sendo assim não será um fator determinante para categorizar o produto.\n",
    "\n",
    "#### 10: weight - peso em gramas da unidade do produto reportado pelo vendedor.\n",
    "** Neste caso deve ser feito uma análise exploratória das distribuições de preços por categorias para identificar se tem alguma correlação do preço com a categorias.\n",
    "Muito provavelmente terá uma alta distribuição, sendo assim não será um fator determinante para categorizar o produto.\n",
    "\n",
    "#### 12: express_delivery - indica se o produto é pronta entrega (1) ou não (0)\n",
    "** Não é um fator determinante para a identificação do produto, não é importante para caracteristica do produto.\n",
    "\n",
    "#### 13: minimum_quantity - quantidade de unidades mínima necessária para compra\n",
    "** Não é um fator determinante para a identificação do produto, não é importante para caracteristica do produto.\n",
    "    \n",
    "#### 14: view_counts - número de cliques no produto nos últimos três meses\n",
    "** Não é um fator determinante para a identificação do produto, não é importante para caracteristica do produto.\n",
    "    \n",
    "#### 15: order_counts - número de vezes que o produto foi comprado nos últimos três meses\n",
    "** Não é um fator determinante para a identificação do produto, não é importante para caracteristica do produto.\n",
    "    \n",
    "#### 16: category - categoria do produto\n",
    "** Categoria do produto cadastrada pelo usuário.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando a base de dados através do conhecimento de negocio os itens relevantes para a determinação do produto são dados de textos livres, não estruturados como o campo \"query\" que é o termo de busca inserido pelo usuário, o campo \"title\", que é o título do produto, e a \"concatenated_tags\", que são as tags do produto inseridas pelo vendedor. \n",
    "Temos o preço (price) e o tamanho (weight) que poderiam ser consideradas caracteristicas relevantes mas só seriam relevantes se existisse alguma correlação forte entre estes campos com a categoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 : Matriz de Correlação de Pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matematicamente podemos criar uma matriz de correlação para identificar as correlações entre os campos, se existem correlações fortes ou fracas entre eles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evidenciar se existem baixa ou alta correlação entre os campos com a categorização dos produtos vamos criar uma matriz de correlação, onde através dela podemos ter uma visão dos valores de correlação de Pearson.\n",
    "Vamos desta forma embasar a nossa avaliar prévia dos campos considerados de baixa correlação com a categorização dos produtos através da matriz de correlação que mederá o grau de relação linear entre cada par de itens disponivel no dataset.\n",
    "Os valores de correlação da matriz são compostos por uma variação entre -1 e +1.\n",
    "Matematicamente a matriz de correlação avaliará a força e a direção da relação entre duas caracteristica.\n",
    "Sendo consideradas variáveis com valores de correlação maiores do que 0,7 tanto positivos como negativos altamente correlacionados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Através da Matriz de correlação podemos notar que os campos 'product_id' , 'seller_id', 'search_page',\n",
    "'position','creation_date', 'express_delivery', 'minimum_quantity', 'view_counts', 'order_counts', não tem nehuma correlação entre eles.\n",
    "Sendo encontrado somente uma correlação de 0.6 entre os campos view_counts e order_counts, porém não representam nenhuma correlação com a categorização do produto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medindo a correlação de pearson da categoria com os campos \"price\" and \"weight\" podemos avaliar que não existem correlações.\n",
    "Tendo o tamanho uma correlação da categoria com o Tamanho de: -0.017 e com o preço de -0.219, ou seja estes campos também não contrubiem para a identificação do produto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Exclução dos campos que não são fatores determinantes para categorização dos produtos  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos então excluir todos os campos do dataset que evidenciamos matematicamente que não possuem correlaçãocom a categoria dos produtos.\n",
    "Sendo eles:\n",
    "\n",
    "###### Campos que não tem correlação matemática com a categorização dos produtos\n",
    "|Campos sem correlação|\n",
    "|-----------------|\n",
    "| 1 - product_id |\n",
    "| 2 - seller_id |\n",
    "| 3 - search_page |\n",
    "| 4 - position |\n",
    "| 5 - creation_date|\n",
    "| 6 - price|\n",
    "| 7 - weight |\n",
    "| 8 - express_delivery |\n",
    "| 9 - minimum_quantity |\n",
    "| 10 - view_counts |\n",
    "| 11 - order_counts|\n",
    "\n",
    "##### Campos de alta correlação usada pelo usuário para categorização do produto\n",
    "\n",
    "|Campos com correlação|\n",
    "|-----------------|\n",
    "| 1 - query |\n",
    "| 2 - title |\n",
    "| 3 - concatenated_tags |\n",
    "\n",
    "\n",
    "##### Campo de categoria\n",
    "\n",
    "|Campos|\n",
    "|-----------------|\n",
    "| 1 - category |\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos 15 itens disponivel no dataset 11 deles não correlação suficiente para a identificação da categoria do produto.\n",
    "Sendo 3 itens de preenchimento de texto livre não estruturado usados pelo usuário para a categorização do produto, como titulo do produto, query de busca do produto e as tags para a busca do produto.\n",
    "Entretando este campos são campos não estruturados, impossibilitando a construção de modelos de tecnicas simples e de média complexidade para a classificação dos produtos pelas caracteristicas disponiveis no dataset.\n",
    "\n",
    "Para a solução do problema baseado nos campos de valores não estruturados precisaremos criar um modelo que seja capaz de aprender baseado em textos livres assim como os seres humanos seriam capazes de categorizar os produtos baseados na análise dos campos como titulo, query e tags.\n",
    "\n",
    "O modelo teria que fazer um minetismo desta forma humana de classificar os produtos através de textos não estruturados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Anaĺise da distribuição das categorias dos produtos no dataset de amostragem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partindo do principio que não temos campos disponiveis no dataset de forma estruturado que sejam relevantes para a identificação da categoria dos produtos.\n",
    "Precisamos avaliar a distribuição das categorias no dataset, a fim de avaliar se temos registros suficientes de cada categoria para que o modelo possa \"aprender\" a classificar o produto a partir das caracteristicas não estruturada disponiveis no dataset.\n",
    "Estão disponiveis no dataset 38.507 registros, sendo:\n",
    "###### Analisar a quantidade de registros por categoria.\n",
    "1: Lembrancinhas     17759; \n",
    "2: Decoração         8846; \n",
    "3: Bebê              7026; \n",
    "4: Papel e Cia       2777; \n",
    "5: Outros            1148.\n",
    "    \n",
    "###### Distribuição de registros por categoria.\n",
    "Tendo a distribuição de: \n",
    "Lembrancinhas:46,12% ;\n",
    "Decoração:22,97%; \n",
    "Bebê:18,24%; \n",
    "Papel e Cia:7,21%;\n",
    "Outros:2,98%.\n",
    "\n",
    "A partir da análise da distribuição podemos avaliar que os produtos com maior porcentagem de registros terão maior possibilidade de serem aprendidos pelo modelo.                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo maior probabilidade o aprendizado do modelo na classificação das Lembrancinhas e de menor probabilidade de identificação da categoria 'Outros', devido a quantidade de registro disponiveis para o treinamento do modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Identificação do Corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que temos os campos,\n",
    "\n",
    "1 - query - termo de busca inserido pelo usuário;\n",
    "\n",
    "2 - title - título do produto e \n",
    "\n",
    "3 - concatenated_tags - tags do produto inseridas pelo vendedor,\n",
    "\n",
    "Precisamos avaliar qual deles teriam o melhor corpus para a identificação do produto.\n",
    "Humanamente avaliando o preenchimento dos 3 campos, podemos observar que os campos query e title tem valores melhores para a identificação da categoria dos produtos, já o campo query tem valores mais sucintos.\n",
    "Um humano lendo apenas 1 destes 3 campos poderia identificar com precisão a categoria dos produtos tendo em mente que temos apenas 5 possiveis categorias.\n",
    "O modelo também teria que ter a mesma habilidade, analisar o campo com melhor corpus para identificação da categoria dos produtos.\n",
    "Lembrando que no caso do modelo ele não terá aprendizagem anterior como um ser humano teria para a identificação dos produtos, o modelo aprenderá apenas com o corpus disponivel no dataset de treinamento, sendo assim, teremos categorias com menor probabilidade de assertividade devida a quantidade limitada de registros, conforme demonstrado na análise de distribuição exposta no passo 4.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análisando as palavras unicas disponivel em cada campo temos:\n",
    "O campo \"title\", com 25.355 palavras.\n",
    "\n",
    "O campo \"tags\", com 23.011 palavras.\n",
    "\n",
    "O campo \"query\", com 6.397 palavras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o corpus que temos de palavras no titulo e nas tags estão muito proximas, estão entre +- 23 mil a +-25 mil. Este seria o nosso tamanho do corpus, ou sejam quantidade de palavras unicas usados para determinar a classificação dos produtos. Através destas palavras um ser humano é capaz de classificar o produto. Olhando o corpus o campos usado para a busca este corpus reduz para +- 6 mil palavras. Precisamos então avaliar qual seria o campos com maior indice de precisão para classificação de produto, um campos com maior quantidade de palavras unicas ou um campo com menor quantidade de palavras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Tratamento do Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que um modelo possa analisar estes dados precisamos transformar estes dados para valores numéricos. \n",
    "Um valor numérico será atribuído a um número de n-grams por sequência.\n",
    "Vamos precisar usar uma função de tokenização, onde está função vai determina um index para cada palavra presente no corpus.\n",
    "Para que o modelo possa analisar estes dados é necessário formatá-los de modo que todas as sequências tenham o mesmo tamanho, que no caso do texto livre podemos analisar que eles tem tamanhos distintos.\n",
    "Então para uma análise de maquina em valores numericos precisamos utilizar uma função que será responsável por truncar as sequências maiores e completar as sequências menores com zeros.\n",
    "Podemos então criar uma função  para criar o corpus para treinamento do modelo com as variaveis title e query. \n",
    "Desta forma podemos testar qual do variavel tem o melhor corpus para o treinamento do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Criação da base do corpus\n",
    "\n",
    "Vamos então criar um conjunto de base de treinamento contendo o corpus disponivel no 'title', onde teremos a variável X contendo os corpus do title e a variável Y contendo a classificação dos produtos, campo 'category', este campo será usado pelo modelo para \"aprender\" dado o corpus qual a categoria, sendo X_title e Y_title..\n",
    "\n",
    "Da mesma forma teremos o corpus de 'query', variável X contendo os corpus do query e a variável Y contendo a classificação dos produtos, sendo X_query, Y_query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo o conjunto de arrays de X_title de tamanho de 38507, 14  and e Y_title 38507, 6.\n",
    "\n",
    "X_query de tamanho de 38507, 15  and e Y_title 38507, 6.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Dataset de Treinamento e Validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que temos então 2 possivel candidatos de corpus para a identificação dos produtos, precisamos então separar o conjunto de treinamento e validação do modelo.\n",
    "Usaremos de cada corpus, 20% para validação e 80% para treinamento.\n",
    "\n",
    "Tendo o dataset de treinamento de 30.805 divididos por 6 para treinamento e 7.702 divididos por 6 para validação do modelo tanto para o corpus de 'title' como o de 'query'.\n",
    "\n",
    "Temos então 30.805 registros para treinamento do modelo e 7.702 registro para a validação do modelo para cada corpus.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a base de dados de treinamento e validação definida precisamos agora pensar na criação de um modelo que seja capaz de \"aprender\" dado o corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Analogia com o Pensamento humano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na análise de correlação feita nos campos disponivel no dataset não foram encontradas caracteristicas estruturadas que tivessem correlação com a categoria do produto. então para que pudessemos criar um modelo de aprendizado usando o corpus precisamos criar um modelo usando tecnicas mais avançadas de treinamento de máquina.\n",
    "\n",
    "Devido a falta de correlação entre as variáveis estruturadas com a categoria, não teremos uma solução pláusivel usando modelos que façam a análise em cima de variaveis estruturadas, por que as variaveis existentes não possuem uma correlação necessária para que um modelo possa classificar o produto dado as caracteristicas estruturadas disponivel para a resolução do problema.\n",
    "\n",
    "Precisamos então neste caso, para resolver o problema com os dados que temos disponiveis explorar técnicas mais avançadas de aprendizado de máquina.\n",
    "\n",
    "O objetivo é criar um modelo que seja capaz de classificar os produtos como os seres humanos fariam, dado que temos somente campos que identifiquem a categoria do produto com textos livres e não estruturados.\n",
    "\n",
    "Fazendo uma analogia com o pensamento humano, se fossemos identificar os produtos através de sua descrição tanto do titulo como na query, nós não começamos a pensar do zero a cada segundo, ou a cada palavra.\n",
    "Nós vamos lendo e interpretando palavra e com base na compreensão das palavras anteriores.\n",
    "Desta forma vamos identificando e classificando o texto.\n",
    "Nós não jogamos fora tudo o que estamos lendo e compreendemos cada palavra com um significado unico, mas vamos lendo as palavras e formando a interpretação baseada na palavra anterior, ou seja nossos pensamentos tem uma  persistência.\n",
    "\n",
    "O modelo também terá que ser capaz de ter esta persistência para poder classificar as categorias dos produtos baseados na descrição do textos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 - Técnica escolhida para desenvolvimento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com modelos tradicionais isso seria impossivel, até mesmo se tratando de redes neurais tradicionais.\n",
    "A necessidade te ter esta persistencia dificulta a aplicação para resolver este problema de classificação de produto baseado em textos não estruturados.\n",
    "\n",
    "Por exemplo, aqui temos um problema onde para a classificação de produtos a partir da descrição temos que não somente usar as palavras, mas levar em consideração as palavras anteriores. Temos que minetizar uma compreensão das frases, assim como um ser humano faria.\n",
    "\n",
    "Um modelo estatístico ou uma rede neural tradicional não seria capaz de ter este aprendizado consistente.\n",
    "\n",
    "Precisamos então usar as Redes Neurais Recorrentes para resolver esse problema, pois estas redes possuem um aprendizado com loops, e isso tecnicamente vai permite que o nosso modelo tenha esta consistencia e \"aprenda\" com informações persistentes, assim como nos seres humanos classificaríamos os produtos lendo os textos.\n",
    "\n",
    "O nosso modelo será baseado em rede neural recorrente que terá redes de múltiplas, sendo cópias da mesma rede.\n",
    "Cada rede passará uma mensagem a rede sucessora, e desta forma criaremos a persistencia que precisamos para resolver o problema de classificação de produto baseado nos textos livres dos campos como titulo ou query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Redes Neurais Recorrentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo a técnica que queremos usar para resolver o problema com redes neurais recorrentes. Vamos utilizar a biblioteca keras para produzir uma rede neural que aprenda a classificar os produtos pelos titulos ou query. Vamos definir as camadas do tipo Embedding, LSTM e Dense da rede, onde:\n",
    "\n",
    "As camadas Embedding servirá para que a rede aprenda as representações mais relevantes para as camandas posteriores.\n",
    "\n",
    "As camanda LSTM permitirá que a sequência seja tratada como um conjunto de dados onde o contexto relevante para que o determinado atributo. \n",
    "\n",
    "As camandas Dense será utilizadas para fazer o processo de transformação da representação produzida pelo LSTM até se atingir a camanda final de neurônios que servirá de camanda de saída."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O corpus máximo será determinado conforme as palavras unicas encontradas em cada corpus.\n",
    "max_features_title = 25355\n",
    "max_features_query = 6397\n",
    "\n",
    "\n",
    "O modelo terá camadas de Embedding de 128 e LSTM de 196.\n",
    "\n",
    "Teremos um dropout de 0.5 para evitar que a rede decorre o cada, ao invés de aprender.\n",
    "\n",
    "Como temos 6 categorias teremos uma Dense de 6 neuromios para determinar as 6 possiveis saidas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Para o modelo de Titulo tem 3.501.422  camadas.\n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "embedding_1 (Embedding)      (None, 14, 128)           3245440   \n",
    "spatial_dropout1d_1 (Spatial (None, 14, 128)           0         \n",
    "lstm_1 (LSTM)                (None, 196)               254800    \n",
    "dense_1 (Dense)               (None, 6)               1182    \n",
    "\n",
    "_______________________________________________________________\n",
    "Total params: 3,501,422\n",
    "Trainable params: 3,501,422\n",
    "Non-trainable params: 0\n",
    "\n",
    "\n",
    "###### Para o modelo de Query tem 1.074.798 camadas.\n",
    "\n",
    "embedding_1 (Embedding)      (None, 15, 128)           818816   \n",
    "spatial_dropout1d_1 (Spatial (None, 15, 128)           0         \n",
    "lstm_1 (LSTM)                (None, 196)               254800    \n",
    "dense_1 (Dense)               (None, 6)               1182    \n",
    "_______________________________________________________________\n",
    "\n",
    "Total params: 1,074,798\n",
    "Trainable params: 1,074,798\n",
    "Non-trainable params: 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 - Treinamento dos modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o treinamento do modelo vamos 20 epocas, ou seja 20 ciclo de treinamento completo no conjunto de treinamento.\n",
    "\n",
    "Vamos testar se os 20 ciclos são suficientes, pois as quantidade de epocas suficientes para convergência variam de dados para dados. \n",
    "\n",
    "Vamos determinar a quantidade de epocas no treinamento quando o erro ficar abaixo de um determinado limite.\n",
    "\n",
    "As 20 epocas também entra no território da prevenção do excesso de ajustes, este é um valor inicial para validação do modelo.\n",
    "\n",
    "                                                                                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 - Perda e acurácia do modelo por epoca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo com aprendizagem no corpus do 'title'\n",
    "Com epocas de 20/20, o modelo de aprendizagem no corpus do titulo obteve: uma perda de 0.1504 e acurácia de 0.9432.\n",
    "\n",
    "##### Modelo com aprendizagem no corpus do 'query'\n",
    "Com epocas de 20/20, o modelo de aprendizagem no corpus do titulo obteve: uma perda de 0.3621 e acurácia de 0.8677.\n",
    "\n",
    "\n",
    "Note que para o modelo de aprendizagem pelo corpus do campo query, seriam necessárias mais epocas para maior aprendizagem do modelo.\n",
    "\n",
    "A principio vamos testar os modelos com o mesmo número de epocas, a fim de, avaliar qual o melhor corpus para utilizarmos para a classificação do modelo baseado em dados não estruturados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13 - Validação da Precisão do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a avaliação dos modelos vamos utilizar as metricas:\n",
    "\n",
    "A acurácia é uma boa indicação geral de como o modelo performou.\n",
    "\n",
    "A precisão pode ser usada em uma situação em que os Falsos Positivos são considerados mais prejudiciais que os Falsos Negativos.\n",
    "\n",
    "O recall pode ser usada em uma situação em que os Falsos Negativos são considerados mais prejudiciais que os Falsos Positivos. \n",
    "\n",
    "O F1-Score é simplesmente uma maneira de observar somente 1 métrica ao invés de duas (precisão e recall) em alguma situação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo de Redes Neurais Recorrentes usando o corpus do campo \"title\"\n",
    "O modelo obteve a acurácia de 88.18% em 7.702 registros de validação.\n",
    "\n",
    "|Category|Precision | Recall   | F1-Score   |\n",
    "|--------|----------|----------|------------|\n",
    "|Bebê                |0.89|0.86|0.88|\n",
    "|Bijuterias e Jóias  |0.93|0.94|0.94|\n",
    "|Decoração           |0.91|0.88|0.90|\n",
    "|Lembrancinhas       |0.90|0.92|0.91|\n",
    "|Papel e Cia         |0.75|0.75|0.75|\n",
    "|Outros              |0.78|0.73|0.76|\n",
    "\n",
    "##### Modelo de Redes Neurais Recorrentes usando o corpus do campo \"query\"\n",
    "O modelo obteve a acurácia de 83.47% em 7.702 registros de validação.\n",
    "\n",
    "|Category|Precision | Recall   | F1-Score   |\n",
    "|--------|----------|----------|------------|\n",
    "|Bebê                |0.89|0.79|0.84|\n",
    "|Bijuterias e Jóias  |0.87|0.85|0.86|\n",
    "|Decoração           |0.86|0.82|0.84|\n",
    "|Lembrancinhas       |0.85|0.92|0.88|\n",
    "|Papel e Cia         |0.79|0.56|0.66|\n",
    "|Outros              |0.81|0.49|0.61|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14 - Conclusão "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado toda a análise exploratória dos dados e as metodologia científica que foram usados na elaboração do solução deste problema podemos concluir que a classificação de produtos baseado no corpus é possivel através de um modelo usando redes neurais recorrentes.\n",
    "\n",
    "O modelo de categorização de produtos usando o corpus do title obteve melhor métrica com menor ciclo de treinamento, tendo -+88,% de acurácia. O modelo usando o corpus do campo 'query' também obteve bons resultados  sendo necessário usar mais epocas para ganho de precisão. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
