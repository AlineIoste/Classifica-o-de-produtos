{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Linha de Raciocínio\n",
    "\n",
    "## Descrição do Problema:\n",
    "\n",
    "Construção de um classificador de produtos que recebe um conjunto de características de um produto e retorna a categoria dele.\n",
    "\n",
    "# Parte 1 - Análise Exploratória\n",
    "\n",
    "### 1 : Anaĺise dos campos que podem ser considerados classificatórios para a identificação do produto\n",
    "\n",
    "O dataset disponivel para a solução do problema é composto de uma amostragem de dados da plataforma do Elo7.\n",
    "O Elo7 é o maior site brasileiro de compra e venda de artesanato. Através da plataforma online compradores podem compra diretamente de milhares de pessoas que transformam ideias criativas em produtos únicos e diferenciados.\n",
    "O dataset disponivel contém 38.507 registros distribuídos em 5 categorias (Bebê, Bijuterias e Jóias, Decoração, Lembrancinhas, Papel e Cia e Outros).\n",
    "Estes registros foram gerados através de cada clique em um produto a partir de um termo de busca do usuário no site.\n",
    "\n",
    "Para construir um modelo classificador de produtos a partir de suas características precisamos analisar se existem campos disponiveis no dataset determinantes para a identificação da categoria dos produtos.\n",
    "\n",
    "Baseado no conhecimento do negocio podemos fazer uma análise prévia dos campos que podem ser determinantes para identificar a categoria dos produtos.\n",
    "\n",
    "Os campos disponivel no dataset devem ser avaliar como uma visão prévia dos possiveis candidatos.\n",
    "\n",
    "#### Análise prévia dos possiveis candidatos \n",
    "\n",
    "* **product_id -** identificação de produto. Não é um fator determinante para a identificação do produto, número sem qualquer correlação com a categoria.\n",
    "* **seller_id** - identificação do vendedor. Não é um fator determinante para a identificação do produto, número de identificação do vendedor, podendo vender qualquer categoria e não sendo uma caracteristica do produto.\n",
    "* **query** - termo de busca inserido pelo usuário. Forte candidato por ter palavras chaves cadastradas pelo vendedor para retornar o produto, ou sejam são incluidas caracterististicas que determimam o produto.\n",
    "* **search_page** - número da página que o produto apareceu nos resultados de busca (mín 1 e máx 5). Não é um fator determinante para identificação do produto, não é importante para caracteristica do produto.\n",
    "* **position** - número da posição que o produto apareceu dentro da página de busca (mín 0 e máx 38). Não é um fator determinante para identificação do produto, não é importante para caracteristica do produto.\n",
    "* **title** - título do produto. Forte candidato por possuir termos cadastrados pelo vendedor para o produto, ou seja são incluidas aqui caracterististicas que determimam o produto.\n",
    "* **concatenated_tags** - tags do produto inseridas pelo vendedor (as tags estão concatenadas por espaço). Forte candidato por possuir termos cadastrados pelo vendedor para retornar o produto.\n",
    "* **creation_date** - data de criação do produto na plataforma do Elo7. Não é um fator determinante para a identificação do produto, não é importante para caracteristica do produto.\n",
    "* **price** - preço do produto em reais. Neste caso deve ser feito uma análise exploratória das distribuições de preços por categorias para identificar se tem alguma correlação do preço com as categorias. Provavelmente terá uma alta distribuição, se esta hipotese for verdadeira, não será um fator determinante para categorizar o produto.\n",
    "* **weight** - peso em gramas da unidade do produto reportado pelo vendedor. Neste caso deve ser feito uma análise exploratória das distribuições de peso por categorias para identificar se tem alguma correlação do peso com as categorias. Provavelmente teremos alta distribuição, sendo assim não será um fator determinante para categorizar o produto.\n",
    "* **express_delivery** - indica se o produto é pronta entrega (1) ou não (0). Não é um fator determinante para a identificação do produto, não é importante para caracteristica do produto.\n",
    "* **minimum_quantity** - quantidade de unidades mínima necessária para compra. Não é um fator determinante para a identificação do produto, não é importante para caracteristica do produto.\n",
    "* **view_counts** - número de cliques no produto nos últimos três meses. Não é um fator determinante para a identificação do produto, não é importante para caracteristica do produto. \n",
    "* **order_counts** - número de vezes que o produto foi comprado nos últimos três meses. Não é um fator determinante para a identificação do produto, não é importante para caracteristica do produto.\n",
    "* **category** - categoria do produto. Categoria do produto cadastrada pelo usuário.\n",
    "\n",
    "Analisando a base de dados através do conhecimento de negócio os itens relevantes para a determinação do produto são dados de textos livres, não estruturados como o campo \"query\" que é o termo de busca inserido pelo usuário, o campo \"title\", que é o título do produto, e a \"concatenated_tags\", que são as tags do produto inseridas pelo vendedor. \n",
    "Temos o preço (price) e o peso (weight) do produto que devem ser avaliados se existisse alguma correlação forte entre eles com a categoria.\n",
    "\n",
    "### 2 : Matriz de Correlação de Pearson\n",
    "\n",
    "Como prova matematicamente da correlação entre os campos podemos criar uma matriz de correlação para demonstrar as correlações entre os campos. Através da matriz de correlação podemos ter uma visão dos valores de correlação entre todos os campos disponiveis no dataset.\n",
    "Desta forma teremos o embasamento matemático para validar a hipotese da análise dos campos de relevância para a identificação da classificação do produto. \n",
    "A avaliação dos campos através da matriz de correlação medirá o grau de relação linear entre cada par de itens disponivel no dataset.\n",
    "Os valores de correlação da matriz são compostos por uma variação entre -1 e +1.\n",
    "Matematicamente a matriz de correlação avaliará a força e a direção da relação entre duas caracteristica, sendo consideradas variáveis altamente correlacionados as variavies que obterem valores de correlação maiores que 0,7 tanto positivos como negativos.\n",
    "\n",
    "### 3 - Anaĺise da distribuição das categorias dos produtos no dataset de amostragem\n",
    "\n",
    "Precisamos avaliar a distribuição das categorias no dataset, a fim de avaliar se temos registros suficientes de cada categoria para que o modelo possa \"aprender\" a classificar o produto.\n",
    "\n",
    "Estão disponiveis no dataset 38.507 registros, sendo:\n",
    "\n",
    "|Categoria|Quantidade|\n",
    "|---------|--------|\n",
    "|Lembrancinhas| 17759|\n",
    "|Decoração| 8846|\n",
    "|Bebê| 7026|\n",
    "|Papel e Cia| 2777|\n",
    "|Outros| 1148|\n",
    "\n",
    "Sendo a distribuição de: \n",
    "\n",
    "|Categoria|Quantidade|\n",
    "|---------|--------|\n",
    "|Lembrancinhas|46,12%|\n",
    "|Decoração|22,97%|\n",
    "|Bebê|18,24%|\n",
    "|Papel e Cia|7,21%|\n",
    "|Outros|2,98%|\n",
    "\n",
    "A partir da análise da distribuição podemos avaliar os produtos com maior porcentagem de registros.\n",
    "Estes produtos terão maior probabilidade de aprendizado do modelo na classificação de suas categorias.\n",
    "\n",
    "\n",
    "\n",
    "### 4 - Exclução dos campos que não são fatores determinantes para categorização dos produtos  \n",
    "\n",
    "Podemos excluir os campos do dataset que evidenciamos matematicamente que não possuem correlação.\n",
    "Sendo os campos que não tem correlação matemática com a categorização dos produtos.\n",
    "\n",
    "###### Hipotese \n",
    "\n",
    "|Id  | Campos sem correlação|\n",
    "|--- |--------------|\n",
    "| 1 -| product_id |\n",
    "| 2 -|seller_id |\n",
    "| 3 -|search_page |\n",
    "| 4 -|position |\n",
    "| 5 -|creation_date|\n",
    "| 6 -|price|\n",
    "| 7 -|weight |\n",
    "| 8 -|express_delivery |\n",
    "| 9 -|minimum_quantity |\n",
    "| 10 |view_counts |\n",
    "| 11 |order_counts|\n",
    "\n",
    "##### Campos de alta correlação usada pelo usuário para categorização do produto\n",
    "\n",
    "|Id  |Campos com correlação|\n",
    "|--- |--------------|\n",
    "| 1 -| query |\n",
    "| 2 -|title |\n",
    "| 3 -|concatenated_tags |\n",
    "\n",
    "\n",
    "##### Campo de categoria\n",
    "\n",
    "|Id  |Campos|\n",
    "|--- |--------------|\n",
    "| 1 -| category |\n",
    "\n",
    "A hipotese é que dos 15 itens disponivel no dataset 11 deles não apresentem correlação suficiente para a identificação da categoria do produto, sendo 3 itens de preenchimento de texto livre não estruturado usados pelo usuário para a categorização do produto, como titulo do produto, query de busca do produto e as tags para a busca do produto.\n",
    "Estes campos não estruturados impossibilitam a construção de modelos por meio de técnicas que necessitam de analises de caracteristicas estruturadas.\n",
    "\n",
    "Para a solução do problema baseado nos campos de valores não estruturados precisaremos criar um modelo que seja capaz de aprender baseado em textos livres, baseados na análise dos campos como titulo, query e tags.\n",
    "\n",
    "O modelo teria que fazer um minetismo da forma humana de classificar os produtos através de textos não estruturados.\n",
    "\n",
    "\n",
    "### 5 - Identificação do Corpus \n",
    "\n",
    "Partindo do principio que não temos campos disponiveis no dataset de forma estruturado que sejam relevantes para a identificação da categoria dos produtos precisamos analisar o corpus nos campos de textos livres.\n",
    "\n",
    "Dado que temos os campos:\n",
    "* query - termo de busca inserido pelo usuário;\n",
    "* title - título do produto e \n",
    "* concatenated_tags - tags do produto inseridas pelo vendedor,\n",
    "\n",
    "Precisamos avaliar qual deles teriam o melhor corpus para a identificação do produto.\n",
    "O modelo deve analisar o campo com melhor corpus para identificação da categoria dos produtos.\n",
    "Uma análise humana lendo apenas 1 destes campos poderia identificar com precisão a categoria dos produtos tendo em mente que temos apenas 5 possiveis categorias.\n",
    "O modelo para a identificação da categoria do produto pelo corpus também teria que ter a mesma habilidade.\n",
    "Lembrando que no caso do modelo, ele não terá aprendizagem anterior como um ser humano teria para a identificação dos produtos.\n",
    "O modelo aprenderá apenas com o corpus disponivel no dataset de treinamento, sendo assim, podemos ter categorias com menor probabilidade de assertividade devido a quantidade limitada de registros, conforme demonstrado na análise de distribuição exposta no passo 4.  \n",
    "\n",
    "##### Análisando as palavras unicas disponivel em cada campo temos:\n",
    "\n",
    "Precisamos analisar o tamanho do corpus disponivel em cada campo.\n",
    "\n",
    "|Campo    |Quantidade|\n",
    "|---------|--------|\n",
    "|title    |25.355|\n",
    "|tags     |23.011|\n",
    "|query    |6.397 |\n",
    "\n",
    "Note que o corpus que temos de palavras no titulo e nas tags estão muito próximas, estão entre 23 mil e 26 mil e para a busca este corpus reduz para +- 6 mil palavras.\n",
    "\n",
    "Precisamos então avaliar qual seria o campos com maior indice de precisão para classificação de produto, o campo com maior quantidade de palavras unicas ou um campo com menor quantidade de palavras.\n",
    "\n",
    "Estes são os valores do tamanho do corpus de cada campo não estruturado, ou seja a quantidade de palavras unicas usados para determinar a classificação dos produtos.\n",
    "\n",
    "Uma análise humana lendo apenas 1 destes campos poderia identificar com precisão a categoria dos produtos tendo em mente que temos apenas 5 possiveis categorias.\n",
    "\n",
    "### 6 - Tratamento do Corpus\n",
    "\n",
    "Para que um modelo possa analisar estes dados precisamos transformar estes dados em valores numéricos. Valores numéricos serão atribuídos a um número de n-grams por sequência.\n",
    "Vamos precisar usar uma função de tokenização que determinará um index para cada palavra presente no corpus.\n",
    "Para que o modelo possa analisar estes dados é necessário formatá-los de modo que todas as sequências tenham o mesmo tamanho, que no caso do texto livre podemos analisar que eles tem tamanhos distintos.\n",
    "Então para uma análise de máquina em valores númericos precisamos utilizar outra função que será responsável por truncar as sequências maiores e completar as sequências menores com zeros.\n",
    "A função criará o corpus para o treinamento do modelo com as variaveis de title e query, e desta forma podemos avaliar qual variavel tem o melhor corpus para o treinamento do modelo.\n",
    "\n",
    "##### Criação da base do corpus\n",
    "\n",
    "Vamos criar um conjunto de base de treinamento contendo o corpus disponivel no 'title', onde teremos a variável X contendo os corpus do title e a variável Y contendo a classificação dos produtos, campo 'category'. \n",
    "Este campo será usado pelo modelo para \"aprender\" através do corpus qual a categoria do produto.\n",
    "Da mesma forma teremos o corpus de 'query', onde a variável X contém o corpus do query e a variável Y contendo a classificação dos produtos.\n",
    "\n",
    "\n",
    "### 7 - Dataset de Treinamento e Validação\n",
    "\n",
    "Dado que temos então 2 possivel candidatos de corpus para a identificação dos produtos, precisamos então separar o conjunto de treinamento e validação do modelo.\n",
    "Usaremos de cada corpus, 20% para validação e 80% para treinamento.\n",
    "\n",
    "Com a base de dados de treinamento e validação definida precisamos agora pensar na criação de um modelo que seja capaz de \"aprender\" dado o corpus.\n",
    "\n",
    "# Parte 2 - Sistema de Classificação de Produtos\n",
    "\n",
    "### 8 - Analogia com o Pensamento humano\n",
    "\n",
    "Na hipotese de análise de correlação feita nos campos disponivel no dataset não foram encontradas caracteristicas estruturadas que tivessem correlação com a categoria do produto.\n",
    "Devido a falta de correlação entre as variáveis estruturadas com a categoria, não teremos uma solução pláusivel usando modelos que façam a análise levando em consideração variaveis estruturadas.\n",
    "\n",
    "Partindo deste premissa para seja possivel criar um modelo de aprendizado através do corpus precisamos criar um modelo usando tecnicas avançadas de treinamento de máquina.\n",
    "\n",
    "O objetivo é criar um modelo que seja capaz de classificar os produtos como os seres humanos fariam, dado que temos somente campos que identifiquem a categoria do produto com textos livres e não estruturados.\n",
    "\n",
    "Fazendo uma analogia com o pensamento humano, se fossemos identificar os produtos através de sua descrição tanto do titulo como na query, nós não analisariamos do zero a cada segundo, ou a cada palavra.\n",
    "Nós interpretamos as palavras com base na compreensão das palavras anteriores. Não compreendemos cada palavra com um significado único, mas vamos lendo as palavras e formando a interpretação baseada na palavra anterior, ou seja nossos pensamentos tem uma persistência.\n",
    "\n",
    "Para resolver este problema através da análise do corpus, o modelo criado também terá que ser capaz de ter esta persistência para poder classificar as categorias dos produtos baseados na descrição do textos.\n",
    "\n",
    "### 9 - Técnica escolhida para desenvolvimento do modelo\n",
    "\n",
    "Com modelos tradicionais seria impossivel a classificação dos produtos pelo corpus, até mesmo se tratando de redes neurais tradicionais.\n",
    "A necessidade de ter esta persistência dificulta a aplicação para resolver este problema de classificação de produto baseado em textos não estruturados.\n",
    "\n",
    "Por exemplo, aqui temos um problema onde para a classificação de produtos a partir da descrição precisamos não somente usar as palavras, mas levar em consideração as palavras anteriores. Temos que minetizar uma compreensão das frases, assim como um ser humano faria.\n",
    "\n",
    "Um modelo estatístico ou uma rede neural tradicional não seria capaz de ter este aprendizado consistente.\n",
    "\n",
    "Precisamos então usar as Redes Neurais Recorrentes para resolver esse problema, pois estas redes possuem um aprendizado com loops, e isso tecnicamente permite que o nosso modelo tenha está consistencia e \"aprenda\" com informações persistentes.\n",
    "\n",
    "O nosso modelo será baseado em rede neural recorrente, tendo redes de múltiplas com cópias da mesma rede.\n",
    "Cada rede passará uma mensagem a rede sucessora e desta forma criaremos a persistencia que precisamos para resolver o problema de classificação de produto baseado nos textos livres dos campos como titulo ou query.\n",
    "\n",
    "### 10 - Redes Neurais Recorrentes\n",
    "\n",
    "Definindo a técnica que melhor se adequa ao problema, sendo as Redes Neurais Recorrentes, precisamos definir as camadas do tipo Embedding, LSTM e Dense da rede, sendo:\n",
    "\n",
    "* **Embedding** que são as camadas da rede que aprende as representações mais relevantes para as camandas posteriores.\n",
    "* **LSTM** que são as camadas da rede que permite que as sequências sejam tratadas como um conjunto de dados onde o contexto relevante para que o determinado atributo. \n",
    "* **Dense** que são as camadas utilizadas para fazer o processo de transformação da representação produzida pelo LSTM até se atingir a camanda final de neurônios que servirá de camanda de saída.\n",
    "\n",
    "O corpus máximo determinado conforme as palavras únicas encontradas em cada corpus.\n",
    "* max_features_title = 25355\n",
    "* max_features_query = 6397\n",
    "\n",
    "O modelo terá camadas de Embedding de 128 e LSTM de 196, e um dropout de 0.5 para evitar que a rede decorre o dado ao invés de aprender.\n",
    "Como temos 6 categorias teremos uma Dense de 6 neuromios para representar as 6 possiveis saidas.\n",
    "\n",
    "\n",
    "#### Para o modelo para corpus do campo Titulo\n",
    "_________________________________________________________________\n",
    "\n",
    "embedding_1 (Embedding)      (None, 14, 128)           3245440   \n",
    "spatial_dropout1d_1 (Spatial (None, 14, 128)           0         \n",
    "lstm_1 (LSTM)                (None, 196)               254800    \n",
    "dense_1 (Dense)               (None, 6)               1182    \n",
    "_______________________________________________________________\n",
    "Total params: 3,501,422\n",
    "Trainable params: 3,501,422\n",
    "Non-trainable params: 0\n",
    "\n",
    "\n",
    "#### Para o modelo para o corpus do campo Query \n",
    "\n",
    "embedding_1 (Embedding)      (None, 15, 128)           818816   \n",
    "spatial_dropout1d_1 (Spatial (None, 15, 128)           0         \n",
    "lstm_1 (LSTM)                (None, 196)               254800    \n",
    "dense_1 (Dense)               (None, 6)               1182    \n",
    "______________________________________________________________\n",
    "Total params: 1,074,798\n",
    "Trainable params: 1,074,798\n",
    "Non-trainable params: 0\n",
    "\n",
    "### 11 - Treinamento dos modelos \n",
    "\n",
    "Para o treinamento do modelo vamos utilizar 20 epocas como ciclos de treinamento completo no conjunto de treinamento.\n",
    "Vamos testar e comparar os modelos usando 20 ciclos, pois as quantidade de epocas suficientes para convergência variam de dados para dados. \n",
    "O objetivo de usar a mesma quantidade de epocas é ter a mesma metrica para avaliar a convergencia dos modelos.\n",
    "A quantidade de epocas no treinamento pode ser interrompida quando o erro ficar abaixo de um valor X determinado.\n",
    "As 20 epocas também entra no território da prevenção do excesso de ajustes, este é um valor inicial para validação dos modelos treinados no corpus do campo title e query.\n",
    "\n",
    "### 12 - Perda e Acurácia do modelo por época\n",
    "\n",
    "A análise dos modelos durante os 20 cliclos de treinamento, é para avaliar os modelos de acordo com cada corpus.\n",
    "\n",
    "Os modelos são comparados com o mesmo número de epocas, a fim de avaliar qual o corpus que podemos utilizar para a classificação do modelo baseado em dados não estruturados.\n",
    "\n",
    "# Parte 3 - Avaliação do Sistema de Classificação\n",
    "\n",
    "### 13 - Validação da Precisão do Modelo\n",
    "\n",
    "Para a avaliação dos modelos podemos utilizar 4 metricas, sendo:\n",
    "\n",
    "* A **acurácia** é uma boa indicação geral de como o modelo performou.\n",
    "* A **precisão** pode ser usada em uma situação em que os Falsos Positivos são considerados mais prejudiciais que os Falsos Negativos.\n",
    "* O recall pode ser usada em uma situação em que os Falsos Negativos são considerados mais prejudiciais que os Falsos Positivos. \n",
    "* O **f1-Score** é simplesmente uma maneira de observar somente 1 métrica ao invés de duas (precisão e recall) em alguma situação.\n",
    "\n",
    "\n",
    "\n",
    "### 14 - Conclusão \n",
    "\n",
    "Levando em consideração toda a análise exploratória dos dados e as metodologia científica que foram usados na elaboração do solução deste problema podemos concluir que a classificação da categoria dos produtos baseado no corpus é possivel,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
